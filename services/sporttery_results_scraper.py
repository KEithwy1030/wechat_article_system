import asyncio
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import time
import re
from datetime import datetime, timedelta
import logging
import subprocess
import psutil

class SportteryResultsScraper:
    """ç«å½©å®˜ç½‘èµ›æœæŠ“å–å™¨"""
    
    def __init__(self):
        self.base_url = "https://www.sporttery.cn/jc/zqsgkj/"
        self.logger = logging.getLogger(__name__)
        
    def _setup_driver(self):
        """è®¾ç½®Chromeé©±åŠ¨ - ä¼˜åŒ–ç‰ˆï¼Œå¢å¼ºåæ£€æµ‹èƒ½åŠ›"""
        from selenium.webdriver.chrome.service import Service
        from webdriver_manager.chrome import ChromeDriverManager
        
        chrome_options = Options()
        
        # åŸºç¡€è®¾ç½®
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        
        # æ€§èƒ½ä¼˜åŒ–
        chrome_options.add_argument('--disable-images')
        chrome_options.add_argument('--disable-plugins')
        chrome_options.add_argument('--disable-extensions')
        chrome_options.add_argument('--disable-web-security')
        chrome_options.add_argument('--disable-features=VizDisplayCompositor')
        
        # åæ£€æµ‹è®¾ç½®
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_argument('--disable-automation')
        chrome_options.add_argument('--disable-infobars')
        chrome_options.add_argument('--disable-extensions-file-access-check')
        chrome_options.add_argument('--disable-extensions-http-throttling')
        
        # ç½‘ç»œè®¾ç½®
        chrome_options.add_argument('--disable-background-timer-throttling')
        chrome_options.add_argument('--disable-backgrounding-occluded-windows')
        chrome_options.add_argument('--disable-renderer-backgrounding')
        chrome_options.add_argument('--disable-field-trial-config')
        
        # ç”¨æˆ·ä»£ç† - ä½¿ç”¨æœ€æ–°çš„Chromeç‰ˆæœ¬
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36')
        
        # å®éªŒæ€§é€‰é¡¹
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation", "enable-logging"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        chrome_options.add_experimental_option("detach", True)
        
        # ç½‘ç»œè¶…æ—¶è®¾ç½®
        chrome_options.add_argument('--timeout=30000')
        chrome_options.add_argument('--page-load-timeout=30000')
        
        # ä½¿ç”¨webdriver-managerè‡ªåŠ¨ä¸‹è½½å¹¶åŒ¹é…Chromeç‰ˆæœ¬
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
        
        # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
        driver.set_page_load_timeout(30)
        driver.implicitly_wait(10)
        
        # æ‰§è¡Œåæ£€æµ‹è„šæœ¬
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
        return driver
    
    async def _cleanup_chrome_processes(self):
        """æ¸…ç†Chromeè¿›ç¨‹ï¼Œé¿å…èµ„æºå†²çª"""
        try:
            print("[æ¸…ç†] æ­£åœ¨æ¸…ç†Chromeè¿›ç¨‹...")
            # æŸ¥æ‰¾å¹¶ç»ˆæ­¢Chromeè¿›ç¨‹
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                try:
                    if proc.info['name'] and 'chrome' in proc.info['name'].lower():
                        cmdline = ' '.join(proc.info['cmdline']) if proc.info['cmdline'] else ''
                        if '--headless' in cmdline or '--remote-debugging-port' in cmdline:
                            print(f"[æ¸…ç†] ç»ˆæ­¢Chromeè¿›ç¨‹: {proc.info['pid']}")
                            proc.terminate()
                            proc.wait(timeout=5)
                except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.TimeoutExpired):
                    pass
            await asyncio.sleep(2)
        except Exception as e:
            print(f"[æ¸…ç†] æ¸…ç†Chromeè¿›ç¨‹æ—¶å‡ºé”™: {e}")
    
    async def scrape_results(self, days_back=3, max_retries=3):
        """æŠ“å–èµ›æœæ•°æ® - å¢å¼ºç‰ˆï¼Œæ”¯æŒé‡è¯•æœºåˆ¶
        
        Args:
            days_back: æŠ“å–å¤šå°‘å¤©å‰çš„èµ›æœï¼Œé»˜è®¤3å¤©
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤3æ¬¡
        """
        print(f"=== å¼€å§‹æŠ“å–ç«å½©å®˜ç½‘èµ›æœ ===")
        print(f"ç›®æ ‡é¡µé¢: {self.base_url}")
        print(f"æœ€å¤§é‡è¯•æ¬¡æ•°: {max_retries}")
        
        # é¦–å…ˆæ¸…ç†å¯èƒ½å­˜åœ¨çš„Chromeè¿›ç¨‹
        await self._cleanup_chrome_processes()
        
        for attempt in range(max_retries):
            driver = None
            try:
                print(f"\n[å°è¯• {attempt + 1}/{max_retries}] åˆå§‹åŒ–WebDriver...")
                driver = self._setup_driver()
                wait = WebDriverWait(driver, 20)
            
                print(f"[å°è¯• {attempt + 1}] è®¿é—®èµ›æœé¡µé¢...")
                driver.get(self.base_url)
                
                # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
                await asyncio.sleep(5)
                
                print(f"é¡µé¢æ ‡é¢˜: {driver.title}")
                print(f"å½“å‰URL: {driver.current_url}")
                
                # æ£€æŸ¥é¡µé¢æ˜¯å¦æ­£å¸¸åŠ è½½
                if "ç«å½©" not in driver.title and "sporttery" not in driver.current_url.lower():
                    raise Exception("é¡µé¢åŠ è½½å¼‚å¸¸ï¼Œå¯èƒ½è¢«åçˆ¬è™«æœºåˆ¶é˜»æ­¢")
                
                print(f"[å°è¯• {attempt + 1}] è®¾ç½®æ—¥æœŸèŒƒå›´...")
                await self._set_date_range(driver, days_back)
                
                print(f"[å°è¯• {attempt + 1}] ç‚¹å‡»æŸ¥è¯¢æŒ‰é’®...")
                await self._click_query_button(driver)
                
                # ç­‰å¾…ç»“æœåŠ è½½
                await asyncio.sleep(5)
                
                print(f"[å°è¯• {attempt + 1}] è§£æèµ›æœæ•°æ®...")
                results = await self._parse_results(driver)
                
                if results:
                    print(f"[æˆåŠŸ] æˆåŠŸæŠ“å–åˆ° {len(results)} æ¡èµ›æœæ•°æ®")
                    return results
                else:
                    print(f"[è­¦å‘Š] å°è¯• {attempt + 1} æ— ç»“æœ")
                    if attempt < max_retries - 1:
                        print(f"ç­‰å¾… 5 ç§’åé‡è¯•...")
                        await asyncio.sleep(5)
                        continue
                    else:
                        print(f"[æœ€ç»ˆ] æ‰€æœ‰å°è¯•å‡æ— ç»“æœï¼Œè¿”å›ç©ºæ•°æ®")
                        return []
                    
            except Exception as e:
                print(f"[é”™è¯¯] å°è¯• {attempt + 1} å¤±è´¥: {e}")
                print(f"[é”™è¯¯] é”™è¯¯ç±»å‹: {type(e).__name__}")
                if attempt < max_retries - 1:
                    print(f"ç­‰å¾… 10 ç§’åé‡è¯•...")
                    await asyncio.sleep(10)
                    continue
                else:
                    print(f"[æœ€ç»ˆ] æ‰€æœ‰å°è¯•å‡å¤±è´¥: {e}")
                    return []
            finally:
                if driver:
                    try:
                        driver.quit()
                        print(f"[æ¸…ç†] WebDriver å·²å…³é—­")
                    except:
                        pass
                
                # æ¸…ç†Chromeè¿›ç¨‹
                await self._cleanup_chrome_processes()
        
        print(f"[å¤±è´¥] æŠ“å–èµ›æœå¤±è´¥ï¼Œå·²å°è¯• {max_retries} æ¬¡")
        return []
    
    async def _set_date_range(self, driver, days_back):
        """è®¾ç½®æ—¥æœŸèŒƒå›´"""
        try:
            # è®¡ç®—æ—¥æœŸèŒƒå›´ - è·å–æœ€è¿‘å‡ å¤©çš„çœŸå®èµ›æœ
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days_back)
            
            start_date_str = start_date.strftime("%Y-%m-%d")
            end_date_str = end_date.strftime("%Y-%m-%d")
            
            print(f"è®¾ç½®æ—¥æœŸèŒƒå›´: {start_date_str} è‡³ {end_date_str}")
            
            # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
            time.sleep(3)
            
            # ç®€åŒ–æ—¥æœŸè®¾ç½® - å°è¯•ç›´æ¥è®¿é—®å¸¦æ—¥æœŸå‚æ•°çš„URL
            current_url = driver.current_url
            if '?' in current_url:
                # å¦‚æœURLå·²æœ‰å‚æ•°ï¼Œæ·»åŠ æ—¥æœŸå‚æ•°
                date_params = f"&startDate={start_date_str}&endDate={end_date_str}"
                new_url = current_url + date_params
            else:
                # å¦‚æœURLæ²¡æœ‰å‚æ•°ï¼Œæ·»åŠ æ—¥æœŸå‚æ•°
                date_params = f"?startDate={start_date_str}&endDate={end_date_str}"
                new_url = current_url + date_params
            
            print(f"å°è¯•è®¿é—®å¸¦æ—¥æœŸå‚æ•°çš„URL: {new_url}")
            driver.get(new_url)
            time.sleep(3)
            
        except Exception as e:
            print(f"è®¾ç½®æ—¥æœŸèŒƒå›´å¤±è´¥: {e}")
            # å°è¯•ç›´æ¥è®¿é—®å¸¦å‚æ•°çš„URLä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
            try:
                param_url = f"{self.base_url}?startDate={start_date_str}&endDate={end_date_str}"
                driver.get(param_url)
                time.sleep(5)
                print("ä½¿ç”¨URLå‚æ•°æ–¹å¼è®¾ç½®æ—¥æœŸ")
            except Exception as e2:
                print(f"URLå‚æ•°æ–¹å¼ä¹Ÿå¤±è´¥: {e2}")
    
    async def _click_query_button(self, driver):
        """ç‚¹å‡»æŸ¥è¯¢æŒ‰é’®"""
        try:
            # ç­‰å¾…é¡µé¢åŠ è½½
            time.sleep(3)
            
            # å°è¯•å¤šç§æ–¹å¼æŸ¥æ‰¾æŸ¥è¯¢æŒ‰é’®ï¼ˆä¼˜å…ˆæŸ¥æ‰¾"å¼€å§‹æŸ¥è¯¢"æŒ‰é’®ï¼‰
            query_selectors = [
                "//button[contains(text(), 'å¼€å§‹æŸ¥è¯¢')]",
                "//button[contains(text(), 'æŸ¥è¯¢')]",
                "//button[contains(text(), 'æœç´¢')]",
                "//input[@type='submit']",
                "//button[@type='submit']",
                "//button[contains(@class, 'btn')]",
                "//button[contains(@class, 'query')]",
                "//button[contains(@class, 'search')]",
                "//button[contains(@id, 'query')]",
                "//button[contains(@id, 'search')]",
                "//a[contains(text(), 'å¼€å§‹æŸ¥è¯¢')]",
                "//a[contains(text(), 'æŸ¥è¯¢')]",
                "//a[contains(text(), 'æœç´¢')]"
            ]
            
            query_button = None
            for selector in query_selectors:
                try:
                    buttons = driver.find_elements(By.XPATH, selector)
                    for button in buttons:
                        if button.is_displayed() and button.is_enabled():
                            query_button = button
                            print(f"æ‰¾åˆ°æŸ¥è¯¢æŒ‰é’®: {selector}")
                            break
                    if query_button:
                        break
                except:
                    continue
            
            if query_button:
                # å°è¯•ç‚¹å‡»
                try:
                    # æ»šåŠ¨åˆ°æŒ‰é’®ä½ç½®
                    driver.execute_script("arguments[0].scrollIntoView(true);", query_button)
                    time.sleep(1)
                    
                    query_button.click()
                    print("ç‚¹å‡»æŸ¥è¯¢æŒ‰é’®æˆåŠŸ")
                    time.sleep(5)  # ç­‰å¾…ç»“æœåŠ è½½
                except Exception as e:
                    # å¦‚æœæ™®é€šç‚¹å‡»å¤±è´¥ï¼Œå°è¯•JavaScriptç‚¹å‡»
                    driver.execute_script("arguments[0].click();", query_button)
                    print("ä½¿ç”¨JavaScriptç‚¹å‡»æŸ¥è¯¢æŒ‰é’®æˆåŠŸ")
                    time.sleep(5)
            else:
                print("æœªæ‰¾åˆ°æŸ¥è¯¢æŒ‰é’®ï¼Œå°è¯•ç›´æ¥æäº¤è¡¨å•")
                # å°è¯•ç›´æ¥æäº¤è¡¨å•
                try:
                    driver.execute_script("document.forms[0].submit();")
                    print("ç›´æ¥æäº¤è¡¨å•æˆåŠŸ")
                    time.sleep(5)
                except:
                    print("è¡¨å•æäº¤ä¹Ÿå¤±è´¥ï¼Œç»§ç»­è§£æå½“å‰é¡µé¢")
                    
        except Exception as e:
            print(f"ç‚¹å‡»æŸ¥è¯¢æŒ‰é’®å¤±è´¥: {e}")
            print("ç»§ç»­å°è¯•è§£æå½“å‰é¡µé¢å†…å®¹")
    
    async def _parse_results(self, driver):
        """è§£æèµ›æœæ•°æ®ï¼ˆæ”¯æŒåˆ†é¡µï¼‰"""
        all_results = []
        
        try:
            # ç­‰å¾…é¡µé¢å†…å®¹åŠ è½½
            time.sleep(2)
            
            # è·å–æ€»é¡µæ•°
            total_pages = await self._get_total_pages(driver)
            print(f"å‘ç°æ€»é¡µæ•°: {total_pages}")
            
            # æ™ºèƒ½æŠ“å–ï¼šæ ¹æ®å®é™…éœ€è¦æŠ“å–èµ›æœ
            print(f"æ™ºèƒ½æŠ“å–ï¼šæ ¹æ®å®é™…éœ€è¦æŠ“å–èµ›æœï¼ˆå·²ç»“æŸä¸”åœ¨æˆ‘ä»¬ç½‘ç«™ä¸­çš„æ¯”èµ›ï¼‰")
            
            # è·å–æˆ‘ä»¬éœ€è¦æŠ“å–èµ›æœçš„æ¯”èµ›åˆ—è¡¨
            needed_matches = await self._get_needed_matches()
            print(f"éœ€è¦æŠ“å–èµ›æœçš„æ¯”èµ›æ•°é‡: {len(needed_matches)}")
            
            if not needed_matches:
                print("[æˆåŠŸ] æ²¡æœ‰éœ€è¦æŠ“å–èµ›æœçš„æ¯”èµ›ï¼Œè·³è¿‡æŠ“å–")
                return []
            
            # æ ¹æ®éœ€è¦çš„æ¯”èµ›æ•°é‡æ™ºèƒ½åˆ¤æ–­æŠ“å–é¡µæ•°
            estimated_pages = min(total_pages, max(1, len(needed_matches) // 20 + 1))
            print(f"[ç›®æ ‡] æ™ºèƒ½åˆ¤æ–­ï¼šé¢„è®¡éœ€è¦æŠ“å– {estimated_pages} é¡µ")
            
            for page_num in range(1, estimated_pages + 1):
                print(f"\n[æŠ“å–] æ­£åœ¨æŠ“å–ç¬¬ {page_num} é¡µ...")
                
                # è§£æå½“å‰é¡µé¢çš„æ•°æ®
                page_results = await self._parse_current_page(driver)
                all_results.extend(page_results)
                print(f"[æˆåŠŸ] ç¬¬ {page_num} é¡µæŠ“å–åˆ° {len(page_results)} æ¡èµ›æœ")
                
                # æ£€æŸ¥æ˜¯å¦å·²ç»æŠ“å–åˆ°è¶³å¤Ÿçš„èµ›æœ
                if len(all_results) >= len(needed_matches) * 2:  # ç•™ä¸€äº›ä½™é‡
                    print(f"[ç›®æ ‡] å·²æŠ“å–åˆ°è¶³å¤Ÿçš„èµ›æœæ•°æ®ï¼Œåœæ­¢æŠ“å–")
                    break
                
                # å¦‚æœä¸æ˜¯æœ€åä¸€é¡µï¼Œç‚¹å‡»ä¸‹ä¸€é¡µ
                if page_num < estimated_pages:
                    if not await self._go_to_next_page(driver, page_num + 1):
                        print(f"[è­¦å‘Š] æ— æ³•è·³è½¬åˆ°ç¬¬ {page_num + 1} é¡µï¼Œåœæ­¢æŠ“å–")
                        break
                    time.sleep(3)  # ç­‰å¾…é¡µé¢åŠ è½½
            
            # å»é‡å¤„ç†
            unique_results = []
            seen_matches = set()
            
            for result in all_results:
                match_key = f"{result.get('match_code', '')}_{result.get('home_team', '')}_{result.get('away_team', '')}"
                if match_key not in seen_matches:
                    seen_matches.add(match_key)
                    unique_results.append(result)
            
            print(f"\nğŸ‰ åˆ†é¡µæŠ“å–å®Œæˆï¼Œæ€»å…±æŠ“å–åˆ° {len(all_results)} æ¡èµ›æœï¼Œå»é‡å {len(unique_results)} æ¡")
            
            # ä¿å­˜èµ›æœåˆ°æ•°æ®åº“
            await self._save_results_to_database(unique_results)
            
            # æ›´æ–°å‘½ä¸­ç‡ç»Ÿè®¡
            await self._update_hit_rate_stats(unique_results)
            
            return unique_results
            
        except Exception as e:
            print(f"[å¤±è´¥] è§£æèµ›æœæ•°æ®å¤±è´¥: {e}")
            return all_results
    
    async def _get_total_pages(self, driver):
        """è·å–æ€»é¡µæ•°"""
        try:
            # æŸ¥æ‰¾åˆ†é¡µæ§ä»¶
            pagination_selectors = [
                "//div[contains(@class, 'pagination')]",
                "//div[contains(@class, 'page')]",
                "//div[contains(@class, 'pager')]",
                "//div[contains(@id, 'page')]",
                "//div[contains(@id, 'pagination')]"
            ]
            
            for selector in pagination_selectors:
                try:
                    pagination = driver.find_element(By.XPATH, selector)
                    if pagination:
                        # æŸ¥æ‰¾é¡µç é“¾æ¥
                        page_links = pagination.find_elements(By.XPATH, ".//a[contains(@href, 'page') or contains(text(), 'ä¸‹åé¡µ') or contains(text(), 'å°¾é¡µ')]")
                        
                        if page_links:
                            # å°è¯•ç‚¹å‡»"å°¾é¡µ"è·å–æ€»é¡µæ•°
                            try:
                                last_page_link = pagination.find_element(By.XPATH, ".//a[contains(text(), 'å°¾é¡µ')]")
                                if last_page_link:
                                    last_page_link.click()
                                    time.sleep(3)
                                    
                                    # è·å–å½“å‰é¡µç 
                                    current_page = driver.find_element(By.XPATH, "//a[contains(@class, 'current') or contains(@class, 'active')]")
                                    total_pages = int(current_page.text)
                                    print(f"[æˆåŠŸ] é€šè¿‡å°¾é¡µè·å–æ€»é¡µæ•°: {total_pages}")
                                    return total_pages
                            except:
                                pass
                        
                        # å¦‚æœæ— æ³•è·å–æ€»é¡µæ•°ï¼Œè¿”å›é»˜è®¤å€¼
                        print("[è­¦å‘Š] æ— æ³•è·å–æ€»é¡µæ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼10")
                        return 10
                except:
                    continue
            
            print("[è­¦å‘Š] æœªæ‰¾åˆ°åˆ†é¡µæ§ä»¶ï¼Œä½¿ç”¨é»˜è®¤å€¼10")
            return 10
            
        except Exception as e:
            print(f"[è­¦å‘Š] è·å–æ€»é¡µæ•°å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼10")
            return 10
    
    async def _parse_current_page(self, driver):
        """è§£æå½“å‰é¡µé¢çš„èµ›æœæ•°æ®"""
        results = []
        
        try:
            # å°è¯•å¤šç§æ–¹å¼æŸ¥æ‰¾èµ›æœæ•°æ®
            data_selectors = [
                "//table",
                "//div[contains(@class, 'result')]",
                "//div[contains(@class, 'match')]",
                "//div[contains(@class, 'game')]",
                "//ul[contains(@class, 'list')]",
                "//div[contains(@class, 'content')]"
            ]
            
            all_tables = []
            for selector in data_selectors:
                try:
                    elements = driver.find_elements(By.XPATH, selector)
                    all_tables.extend(elements)
                except:
                    continue
            
            for table_idx, table in enumerate(all_tables):
                # è·å–æ‰€æœ‰è¡Œï¼ˆtræˆ–liï¼‰
                rows = []
                try:
                    rows.extend(table.find_elements(By.TAG_NAME, 'tr'))
                except:
                    pass
                try:
                    rows.extend(table.find_elements(By.TAG_NAME, 'li'))
                except:
                    pass
                try:
                    rows.extend(table.find_elements(By.TAG_NAME, 'div'))
                except:
                    pass
                
                for row_idx, row in enumerate(rows):
                    try:
                        # è·å–å•å…ƒæ ¼
                        cells = []
                        try:
                            cells.extend(row.find_elements(By.TAG_NAME, 'td'))
                        except:
                            pass
                        try:
                            cells.extend(row.find_elements(By.TAG_NAME, 'span'))
                        except:
                            pass
                        try:
                            cells.extend(row.find_elements(By.TAG_NAME, 'div'))
                        except:
                            pass
                        
                        if len(cells) < 3:  # è‡³å°‘éœ€è¦3åˆ—æ•°æ®
                            continue
                        
                        # è§£ææ¯”èµ›æ•°æ®
                        match_data = self._parse_match_row(cells)
                        if match_data:
                            results.append(match_data)
                    
                    except Exception as e:
                        continue
            
            return results
            
        except Exception as e:
            print(f"[å¤±è´¥] è§£æå½“å‰é¡µé¢å¤±è´¥: {e}")
            return results
    
    async def _go_to_next_page(self, driver, page_num):
        """è·³è½¬åˆ°ä¸‹ä¸€é¡µ"""
        try:
            # æŸ¥æ‰¾åˆ†é¡µæ§ä»¶
            pagination_selectors = [
                "//div[contains(@class, 'pagination')]",
                "//div[contains(@class, 'page')]",
                "//div[contains(@class, 'pager')]"
            ]
            
            for selector in pagination_selectors:
                try:
                    pagination = driver.find_element(By.XPATH, selector)
                    if pagination:
                        # å°è¯•ç‚¹å‡»æŒ‡å®šé¡µç 
                        try:
                            page_link = pagination.find_element(By.XPATH, f".//a[text()='{page_num}']")
                            if page_link:
                                page_link.click()
                                time.sleep(2)
                                return True
                        except:
                            pass
                        
                        # å°è¯•ç‚¹å‡»"ä¸‹ä¸€é¡µ"
                        try:
                            next_link = pagination.find_element(By.XPATH, ".//a[contains(text(), 'ä¸‹ä¸€é¡µ') or contains(text(), 'ä¸‹åé¡µ')]")
                            if next_link:
                                next_link.click()
                                time.sleep(2)
                                return True
                        except:
                            pass
                except:
                    continue
            
            return False
            
        except Exception as e:
            print(f"[è­¦å‘Š] è·³è½¬ä¸‹ä¸€é¡µå¤±è´¥: {e}")
            return False
    
    async def _parse_page_text(self, driver):
        """è§£æé¡µé¢æ–‡æœ¬å†…å®¹"""
        try:
            print("[æŸ¥æ‰¾] å°è¯•è§£æé¡µé¢æ–‡æœ¬å†…å®¹...")
            
            # è·å–é¡µé¢æ–‡æœ¬
            page_text = driver.page_source
            print(f"é¡µé¢æ–‡æœ¬é•¿åº¦: {len(page_text)} å­—ç¬¦")
            
            # æŸ¥æ‰¾åŒ…å«æ¯”èµ›ä¿¡æ¯çš„æ–‡æœ¬æ¨¡å¼
            import re
            
            # æ¯”èµ›ä»£ç æ¨¡å¼
            match_code_pattern = r'(å‘¨[ä¸€äºŒä¸‰å››äº”å…­æ—¥]\d{3})'
            match_codes = re.findall(match_code_pattern, page_text)
            print(f"æ‰¾åˆ° {len(match_codes)} ä¸ªæ¯”èµ›ä»£ç ")
            
            # æ¯”åˆ†æ¨¡å¼
            score_pattern = r'(\d+:\d+)'
            scores = re.findall(score_pattern, page_text)
            print(f"æ‰¾åˆ° {len(scores)} ä¸ªæ¯”åˆ†")
            
            # é˜Ÿåæ¨¡å¼
            team_pattern = r'([\u4e00-\u9fff]+(?:\([^)]*\))?)\s*VS\s*([\u4e00-\u9fff]+(?:\([^)]*\))?)'
            teams = re.findall(team_pattern, page_text)
            print(f"æ‰¾åˆ° {len(teams)} ä¸ªé˜Ÿåå¯¹")
            
            # ç»„åˆæ•°æ®
            results = []
            for i, match_code in enumerate(match_codes):
                if i < len(teams) and i < len(scores):
                    home_team, away_team = teams[i]
                    score = scores[i]
                    
                    result = {
                        'match_code': match_code,
                        'home_team': home_team,
                        'away_team': away_team,
                        'full_score': score,
                        'status': 'å·²å®Œæˆ',
                        'scraped_at': datetime.now().isoformat()
                    }
                    results.append(result)
                    print(f"[æˆåŠŸ] æ–‡æœ¬è§£ææ¯”èµ›: {match_code} - {home_team} VS {away_team} - {score}")
            
            return results
            
        except Exception as e:
            print(f"[å¤±è´¥] è§£æé¡µé¢æ–‡æœ¬å¤±è´¥: {e}")
            return []
    
    def _parse_match_row(self, cells):
        """è§£æå•è¡Œæ¯”èµ›æ•°æ®"""
        try:
            if len(cells) < 6:
                return None
            
            # æå–åŸºæœ¬ä¿¡æ¯
            match_data = {
                'match_date': cells[0].text.strip() if len(cells) > 0 else '',
                'match_code': cells[1].text.strip() if len(cells) > 1 else '',
                'league': cells[2].text.strip() if len(cells) > 2 else '',
                'teams': cells[3].text.strip() if len(cells) > 3 else '',
                'half_score': cells[4].text.strip() if len(cells) > 4 else '',
                'full_score': cells[5].text.strip() if len(cells) > 5 else '',
                'status': cells[9].text.strip() if len(cells) > 9 else '',
                'scraped_at': datetime.now().isoformat()
            }
            
            # è§£æå¯¹é˜µåŒæ–¹
            teams_text = match_data['teams']
            
            # å¤„ç†å„ç§VSæ ¼å¼
            if ' VS ' in teams_text:
                # æ ‡å‡†æ ¼å¼ï¼šä¸»é˜Ÿ VS å®¢é˜Ÿ
                parts = teams_text.split(' VS ')
                match_data['home_team'] = parts[0].strip()
                match_data['away_team'] = parts[1].strip()
            elif 'VS' in teams_text:
                # æ— ç©ºæ ¼æ ¼å¼ï¼šä¸»é˜ŸVSå®¢é˜Ÿ
                parts = teams_text.split('VS')
                if len(parts) == 2:
                    match_data['home_team'] = parts[0].strip()
                    match_data['away_team'] = parts[1].strip()
                else:
                    match_data['home_team'] = teams_text
                    match_data['away_team'] = ''
            else:
                match_data['home_team'] = teams_text
                match_data['away_team'] = ''
            
            # æ¸…ç†é˜Ÿåï¼šç§»é™¤æ‹¬å·å†…å®¹ï¼ˆå¦‚è®©çƒä¿¡æ¯ï¼‰
            if match_data['home_team']:
                # ç§»é™¤æ‹¬å·åŠå…¶å†…å®¹
                import re
                match_data['home_team'] = re.sub(r'\([^)]*\)', '', match_data['home_team']).strip()
            if match_data['away_team']:
                match_data['away_team'] = re.sub(r'\([^)]*\)', '', match_data['away_team']).strip()
            
            # éªŒè¯æ•°æ®å®Œæ•´æ€§
            if not match_data['match_code'] or not match_data['full_score']:
                return None
            
            # åªè¿”å›å·²å®Œæˆçš„æ¯”èµ›
            if match_data['status'] != 'å·²å®Œæˆ':
                return None
            
            return match_data
            
        except Exception as e:
            print(f"[è­¦å‘Š] è§£ææ¯”èµ›è¡Œå¤±è´¥: {e}")
            return None

    async def _get_needed_matches(self):
        """è·å–éœ€è¦æŠ“å–èµ›æœçš„æ¯”èµ›åˆ—è¡¨"""
        try:
            import sqlite3
            from datetime import datetime, timedelta
            
            # è¿æ¥æ•°æ®åº“
            conn = sqlite3.connect("system.db")
            cursor = conn.cursor()
            
            # æŸ¥è¯¢éœ€è¦æŠ“å–èµ›æœçš„æ¯”èµ›ï¼šå®˜æ–¹èµ›ç¨‹ä¸å†å²èµ›ç¨‹ä¸­ç¼ºå°‘èµ›æœçš„æ¯”èµ›éƒ½è¦æŠ“
            cursor.execute("""
                SELECT m.match_code, m.home_team, m.away_team, m.league, m.match_time
                FROM lottery_matches m
                LEFT JOIN lottery_results mr ON m.match_code = mr.match_code
                WHERE (mr.full_score IS NULL OR mr.full_score = '')
                ORDER BY m.match_time DESC
            """)
            
            needed_matches = cursor.fetchall()
            conn.close()
            
            return needed_matches
            
        except Exception as e:
            print(f"[è­¦å‘Š] è·å–éœ€è¦æŠ“å–èµ›æœçš„æ¯”èµ›å¤±è´¥: {e}")
            return []
    
    async def _save_results_to_database(self, results):
        """ä¿å­˜èµ›æœåˆ°æ•°æ®åº“ - æ”¹è¿›åŒ¹é…é€»è¾‘"""
        try:
            import sqlite3
            import re
            from datetime import datetime
            
            conn = sqlite3.connect("system.db")
            cursor = conn.cursor()
            
            # è·å–æ•°æ®åº“ä¸­çš„æ¯”èµ›æ•°æ®
            cursor.execute('''
                SELECT match_code, home_team, away_team, league, match_time
                FROM lottery_matches 
                WHERE match_time >= date('now', '-7 days')
                ORDER BY match_time DESC
            ''')
            
            db_matches = cursor.fetchall()
            print(f"[åˆ—è¡¨] æ•°æ®åº“ä¸­æœ‰ {len(db_matches)} åœºæ¯”èµ›éœ€è¦åŒ¹é…")
            
            def clean_team_name(name):
                """æ¸…ç†é˜Ÿå"""
                if not name:
                    return ""
                # ç§»é™¤æ‹¬å·å†…å®¹ï¼Œå¦‚ "æ‹œä»(-3)" -> "æ‹œä»"
                name = re.sub(r'\([^)]*\)', '', name)
                # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä½†ä¿ç•™ä¸­æ–‡å­—ç¬¦å’Œå­—æ¯
                name = re.sub(r'[^\u4e00-\u9fffA-Za-z0-9\s]', '', name)
                return name.strip()
            
            def find_match_by_teams(scraped_result, db_matches):
                """é€šè¿‡é˜Ÿä¼åç§°åŒ¹é…æ¯”èµ›"""
                scraped_home = clean_team_name(scraped_result.get('home_team', ''))
                scraped_away = clean_team_name(scraped_result.get('away_team', ''))
                scraped_league = scraped_result.get('league', '').strip()
                
                for db_match in db_matches:
                    db_code, db_home, db_away, db_league, db_time = db_match
                    db_home = clean_team_name(db_home)
                    db_away = clean_team_name(db_away)
                    db_league = db_league.strip()
                    
                    # é˜Ÿä¼åç§°åŒ¹é…ï¼ˆåŒ…å«å…³ç³»ï¼‰
                    home_match = (scraped_home in db_home or db_home in scraped_home) and len(scraped_home) > 1 and len(db_home) > 1
                    away_match = (scraped_away in db_away or db_away in scraped_away) and len(scraped_away) > 1 and len(db_away) > 1
                    
                    # è”èµ›åŒ¹é…ï¼ˆå¯é€‰ï¼‰
                    league_match = True
                    if scraped_league and db_league:
                        league_match = scraped_league in db_league or db_league in scraped_league
                    
                    if home_match and away_match and league_match:
                        return db_code
                    elif home_match and away_match:
                        return db_code
                
                return None
            
            saved_count = 0
            matched_count = 0
            
            for result in results:
                match_code = result.get('match_code', '')
                home_team = result.get('home_team', '')
                away_team = result.get('away_team', '')
                full_score = result.get('full_score', '')
                half_score = result.get('half_score', '')
                status = result.get('status', 'å·²å®Œæˆ')
                
                if not full_score:
                    continue
                
                # é¦–å…ˆå°è¯•é€šè¿‡æ¯”èµ›ä»£ç åŒ¹é…
                found_match_code = None
                if match_code:
                    cursor.execute('SELECT match_code FROM lottery_matches WHERE match_code = ?', (match_code,))
                    if cursor.fetchone():
                        found_match_code = match_code
                
                # å¦‚æœæ¯”èµ›ä»£ç åŒ¹é…å¤±è´¥ï¼Œå°è¯•é€šè¿‡é˜Ÿä¼åç§°åŒ¹é…
                if not found_match_code:
                    found_match_code = find_match_by_teams(result, db_matches)
                
                if found_match_code:
                    matched_count += 1
                    
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨èµ›æœ
                    cursor.execute('SELECT id FROM lottery_results WHERE match_code = ?', (found_match_code,))
                    existing = cursor.fetchone()
                    
                    if not existing:
                        # æ’å…¥æ–°è®°å½•
                        cursor.execute('''
                            INSERT INTO lottery_results 
                            (match_code, home_team, away_team, half_score, full_score, status, source, scraped_at, created_at, updated_at)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        ''', (
                            found_match_code,
                            home_team,
                            away_team,
                            half_score,
                            full_score,
                            status,
                            'sporttery_improved',
                            result.get('scraped_at', datetime.now().isoformat()),
                            datetime.now().isoformat(),
                            datetime.now().isoformat()
                        ))
                        saved_count += 1
                        print(f"[æˆåŠŸ] ä¿å­˜èµ›æœ: {found_match_code} - {home_team} vs {away_team} - {full_score}")
                    else:
                        print(f"[è·³è¿‡] è·³è¿‡: {found_match_code} - èµ›æœå·²å­˜åœ¨")
                else:
                    print(f"[å¤±è´¥] æœªåŒ¹é…: {home_team} vs {away_team} - {full_score}")
            
            conn.commit()
            conn.close()
            
            print(f"ğŸ‰ åŒ¹é…å®Œæˆ: æˆåŠŸåŒ¹é… {matched_count} æ¡ï¼Œæ–°ä¿å­˜ {saved_count} æ¡èµ›æœåˆ°æ•°æ®åº“")
            
        except Exception as e:
            print(f"[å¤±è´¥] ä¿å­˜èµ›æœåˆ°æ•°æ®åº“å¤±è´¥: {e}")
    
    async def _update_hit_rate_stats(self, results):
        """æ›´æ–°å‘½ä¸­ç‡ç»Ÿè®¡ï¼ˆåŸºäºåˆ†ç»„å®ŒæˆçŠ¶æ€ï¼‰"""
        try:
            from services.lottery.prediction_manager import prediction_manager

            triggered_groups = set()
            processed_matches = 0
            for result in results:
                match_code = result.get('match_code', '')
                full_score = result.get('full_score', '')

                if match_code and full_score:
                    processed_matches += 1
                    update_info = prediction_manager.update_match_result_in_schedule(
                        match_code,
                        full_score,
                        result.get('half_score')
                    )
                    if update_info.get('group_completed'):
                        triggered_groups.add(update_info.get('group_date'))

            print(f"[ç›®æ ‡] å‘½ä¸­ç‡æ£€æŸ¥å®Œæˆï¼Œå…±å¤„ç† {processed_matches} åœºæ¯”èµ›ï¼Œè§¦å‘åˆ†ç»„ {len(triggered_groups)} ä¸ª")

        except Exception as e:
            print(f"[å¤±è´¥] æ›´æ–°å‘½ä¸­ç‡ç»Ÿè®¡å¤±è´¥: {e}")
    
    async def _generate_mock_results(self):
        """ç”Ÿæˆæ¨¡æ‹Ÿèµ›æœæ•°æ®ç”¨äºæµ‹è¯•"""
        try:
            print("[æ¨¡æ‹Ÿ] å¼€å§‹ç”Ÿæˆæ¨¡æ‹Ÿèµ›æœæ•°æ®...")
            
            # è·å–æ•°æ®åº“ä¸­çš„æ¯”èµ›æ•°æ®
            import sqlite3
            conn = sqlite3.connect("system.db")
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT match_code, home_team, away_team, league, match_time
                FROM lottery_matches 
                WHERE match_time >= date('now', '-7 days')
                ORDER BY match_time DESC
            ''')
            
            db_matches = cursor.fetchall()
            conn.close()
            
            if not db_matches:
                print("[æ¨¡æ‹Ÿ] æ•°æ®åº“ä¸­æ²¡æœ‰æ¯”èµ›æ•°æ®ï¼Œç”Ÿæˆé»˜è®¤æ¨¡æ‹Ÿæ•°æ®")
                return [
                    {
                        'match_code': 'å‘¨ä¸€001',
                        'home_team': 'æ›¼åŸ',
                        'away_team': 'é˜¿æ£®çº³',
                        'league': 'è‹±è¶…',
                        'full_score': '2:1',
                        'half_score': '1:0',
                        'status': 'å·²å®Œæˆ',
                        'scraped_at': datetime.now().isoformat()
                    },
                    {
                        'match_code': 'å‘¨ä¸€002',
                        'home_team': 'æ‹œä»æ…•å°¼é»‘',
                        'away_team': 'å¤šç‰¹è’™å¾·',
                        'league': 'å¾·ç”²',
                        'full_score': '3:2',
                        'half_score': '2:1',
                        'status': 'å·²å®Œæˆ',
                        'scraped_at': datetime.now().isoformat()
                    }
                ]
            
            # ä¸ºæ•°æ®åº“ä¸­çš„æ¯”èµ›ç”Ÿæˆæ¨¡æ‹Ÿèµ›æœ
            mock_results = []
            import random
            
            for match in db_matches:
                match_code, home_team, away_team, league, match_time = match
                
                # ç”Ÿæˆéšæœºæ¯”åˆ†
                home_score = random.randint(0, 4)
                away_score = random.randint(0, 4)
                
                # ç”ŸæˆåŠåœºæ¯”åˆ†ï¼ˆé€šå¸¸æ¯”å…¨åœºæ¯”åˆ†å°ï¼‰
                half_home = random.randint(0, min(home_score, 2))
                half_away = random.randint(0, min(away_score, 2))
                
                result = {
                    'match_code': match_code,
                    'home_team': home_team,
                    'away_team': away_team,
                    'league': league,
                    'full_score': f"{home_score}:{away_score}",
                    'half_score': f"{half_home}:{half_away}",
                    'status': 'å·²å®Œæˆ',
                    'scraped_at': datetime.now().isoformat()
                }
                mock_results.append(result)
                
                print(f"[æ¨¡æ‹Ÿ] ç”Ÿæˆèµ›æœ: {match_code} - {home_team} vs {away_team} - {home_score}:{away_score}")
            
            print(f"[æ¨¡æ‹Ÿ] æˆåŠŸç”Ÿæˆ {len(mock_results)} æ¡æ¨¡æ‹Ÿèµ›æœæ•°æ®")
            
            # ä¿å­˜æ¨¡æ‹Ÿæ•°æ®åˆ°æ•°æ®åº“
            if mock_results:
                await self._save_results_to_database(mock_results)
            
            return mock_results
            
        except Exception as e:
            print(f"[å¤±è´¥] ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®å¤±è´¥: {e}")
            return []

# æµ‹è¯•å‡½æ•°
async def test_scraper():
    """æµ‹è¯•èµ›æœæŠ“å–å™¨"""
    scraper = SportteryResultsScraper()
    results = await scraper.scrape_results(days_back=2)
    
    print(f"\n=== æŠ“å–ç»“æœæ±‡æ€» ===")
    print(f"æ€»å…±æŠ“å–åˆ° {len(results)} æ¡èµ›æœ")
    
    for i, result in enumerate(results[:5]):  # æ˜¾ç¤ºå‰5æ¡
        print(f"\nèµ›æœ {i+1}:")
        print(f"  æ¯”èµ›ç¼–å·: {result.get('match_code', 'N/A')}")
        print(f"  è”èµ›: {result.get('league', 'N/A')}")
        print(f"  å¯¹é˜µ: {result.get('home_team', '')} VS {result.get('away_team', '')}")
        print(f"  åŠåœºæ¯”åˆ†: {result.get('half_score', 'N/A')}")
        print(f"  å…¨åœºæ¯”åˆ†: {result.get('full_score', 'N/A')}")
        print(f"  çŠ¶æ€: {result.get('status', 'N/A')}")

if __name__ == "__main__":
    asyncio.run(test_scraper())
